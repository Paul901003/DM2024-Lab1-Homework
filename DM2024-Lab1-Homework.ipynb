{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Student Information\n",
    "Name:\n",
    "\n",
    "Student ID:\n",
    "\n",
    "GitHub ID:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. First: do the **take home** exercises in the [DM2024-Lab1-Master](https://github.com/didiersalazar/DM2024-Lab1-Master.git). You may need to copy some cells from the Lab notebook to this notebook. __This part is worth 20% of your grade.__\n",
    "\n",
    "\n",
    "2. Second: follow the same process from the [DM2024-Lab1-Master](https://github.com/didiersalazar/DM2024-Lab1-Master.git) on **the new dataset**. You don't need to explain all details as we did (some **minimal comments** explaining your code are useful though).  __This part is worth 30% of your grade.__\n",
    "    - Download the [the new dataset](https://huggingface.co/datasets/Senem/Nostalgic_Sentiment_Analysis_of_YouTube_Comments_Data). The dataset contains a `sentiment` and `comment` columns, with the sentiment labels being: 'nostalgia' and 'not nostalgia'. Read the specificiations of the dataset for background details. \n",
    "    - You are allowed to use and modify the `helper` functions in the folder of the first lab session (notice they may need modification) or create your own.\n",
    "\n",
    "\n",
    "3. Third: please attempt the following tasks on **the new dataset**. __This part is worth 30% of your grade.__\n",
    "    - Generate meaningful **new data visualizations**. Refer to online resources and the Data Mining textbook for inspiration and ideas. \n",
    "    - Generate **TF-IDF features** from the tokens of each text. This will generating a document matrix, however, the weights will be computed differently (using the TF-IDF value of each word per document as opposed to the word frequency). Refer to this Scikit-learn [guide](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html) .\n",
    "    - Implement a simple **Naive Bayes classifier** that automatically classifies the records into their categories. Use both the TF-IDF features and word frequency features to build two seperate classifiers. Note that for the TF-IDF features you might need to use other type of NB classifier different than the one in the Master Notebook. Comment on the differences.  Refer to this [article](https://hub.packtpub.com/implementing-3-naive-bayes-classifiers-in-scikit-learn/).\n",
    "\n",
    "\n",
    "4. Fourth: In the lab, we applied each step really quickly just to illustrate how to work with your dataset. There are somethings that are not ideal or the most efficient/meaningful. Each dataset can be handled differently as well. What are those inefficent parts you noticed? How can you improve the Data preprocessing for these specific datasets? __This part is worth 10% of your grade.__\n",
    "\n",
    "\n",
    "5. Fifth: It's hard for us to follow if your code is messy, so please **tidy up your notebook** and **add minimal comments where needed**. __This part is worth 10% of your grade.__\n",
    "\n",
    "\n",
    "You can submit your homework following these guidelines: [Git Intro & How to hand your homework](https://github.com/didiersalazar/DM2024-Lab1-Master/blob/main/Git%20Intro%20%26%20How%20to%20hand%20your%20homework.ipynb). Make sure to commit and save your changes to your repository __BEFORE the deadline (October 27th 11:59 pm, Sunday)__. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'datasets'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m### Begin Assignment Here\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_dataset\n\u001b[0;32m      4\u001b[0m ds \u001b[38;5;241m=\u001b[39m load_dataset(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSenem/Nostalgic_Sentiment_Analysis_of_YouTube_Comments_Data\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'datasets'"
     ]
    }
   ],
   "source": [
    "### Begin Assignment Here\n",
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"Senem/Nostalgic_Sentiment_Analysis_of_YouTube_Comments_Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "from datasets import load_dataset\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "dataset = load_dataset(\"Senem/Nostalgic_Sentiment_Analysis_of_YouTube_Comments_Data\")\n",
    "df = pd.DataFrame(dataset['train'])\n",
    "\n",
    "nostalgia_comments = df[df['sentiment'] == 'nostalgia']['comment']\n",
    "not_nostalgia_comments = df[df['sentiment'] == 'not nostalgia']['comment']\n",
    "\n",
    "# CountVectorizer詞頻\n",
    "vectorizer = CountVectorizer(stop_words='english', max_features=10)  # max_features=10 表示取出最常見的10個詞\n",
    "nostalgia_word_counts = vectorizer.fit_transform(nostalgia_comments).toarray().sum(axis=0)\n",
    "not_nostalgia_word_counts = vectorizer.fit_transform(not_nostalgia_comments).toarray().sum(axis=0)\n",
    "\n",
    "words = vectorizer.get_feature_names_out()\n",
    "nostalgia_df = pd.DataFrame({'word': words, 'count': nostalgia_word_counts, 'label': 'nostalgia'})\n",
    "not_nostalgia_df = pd.DataFrame({'word': words, 'count': not_nostalgia_word_counts, 'label': 'not nostalgia'})\n",
    "word_counts_df = pd.concat([nostalgia_df, not_nostalgia_df])\n",
    "\n",
    "# 畫出長條圖\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(data=word_counts_df, x='word', y='count', hue='label')\n",
    "plt.title('Nostalgia & Not Nostalgia')\n",
    "plt.legend(title='lable')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "sns.countplot(data=df, x='sentiment')\n",
    "plt.show()\n",
    "\n",
    "# 詞雲\n",
    "all_text = ' '.join(df['comment'])\n",
    "wordcloud = WordCloud(width=800, height=400, background_color='white').generate(all_text)\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# 計算情感標籤的比例\n",
    "sentiment_counts = df['sentiment'].value_counts()\n",
    "labels = sentiment_counts.index\n",
    "sizes = sentiment_counts.values\n",
    "\n",
    "# 繪製圓餅圖\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.pie(sizes, labels=labels)\n",
    "plt.title('nostalgia vs. not nostalgia')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "#參考:https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(df['comment'])\n",
    "y = df['sentiment'].apply(lambda x: 1 if x == 'nostalgia' else 0)\n",
    "print(y.shape)\n",
    "print(X_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"Senem/Nostalgic_Sentiment_Analysis_of_YouTube_Comments_Data\")\n",
    "df = pd.DataFrame(dataset['train'])\n",
    "\n",
    "df['label'] = df['sentiment'].apply(lambda x: 1 if x == 'nostalgia' else 0)\n",
    "X = df['comment']\n",
    "y = df['label']\n",
    "\n",
    "\n",
    "# Split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "# 詞頻\n",
    "count_vectorizer = CountVectorizer()\n",
    "X_train_counts = count_vectorizer.fit_transform(X_train)\n",
    "X_test_counts = count_vectorizer.transform(X_test)\n",
    "\n",
    "# Multinomial\n",
    "nb_count = MultinomialNB()\n",
    "nb_count.fit(X_train_counts, y_train)\n",
    "y_pred_count = nb_count.predict(X_test_counts)\n",
    "print(\"Multinomial NB_詞頻:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_count))\n",
    "print(classification_report(y_test, y_pred_count))\n",
    "\n",
    "nb_tfidf = MultinomialNB()\n",
    "nb_tfidf.fit(X_train_tfidf, y_train)\n",
    "y_pred_tfidf = nb_tfidf.predict(X_test_tfidf)\n",
    "print(\"\\nMultinomial NB_TF-IDF:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_tfidf))\n",
    "print(classification_report(y_test, y_pred_tfidf))\n",
    "\n",
    "# Bernoulli\n",
    "nb_count1 = BernoulliNB()\n",
    "nb_count1.fit(X_train_counts, y_train)\n",
    "y_pred_count = nb_count1.predict(X_test_counts)\n",
    "print(\"Bernoulli NB_詞頻:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_count))\n",
    "print(classification_report(y_test, y_pred_count))\n",
    "\n",
    "nb_tfidf1 = BernoulliNB()\n",
    "nb_tfidf1.fit(X_train_tfidf, y_train)\n",
    "y_pred_tfidf = nb_tfidf1.predict(X_test_tfidf)\n",
    "print(\"\\nBernoulli NB_TF-IDF:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_tfidf))\n",
    "print(classification_report(y_test, y_pred_tfidf))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
